{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af6e92a",
   "metadata": {},
   "source": [
    "# UNET Fetal A.P Diameter of Pons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b130e1e",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478c8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a07da",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e629b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGen(keras.utils.Sequence):\n",
    "    def __init__(self, ids, path, batch_size=8, image_size=128):\n",
    "        self.ids = ids\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __load__(self, id_name):\n",
    "        ## Path\n",
    "        img_path = os.path.join(self.path, id_name)\n",
    "        all_imgs = os.listdir(img_path)\n",
    "        \n",
    "        mask = np.zeros((self.image_size, self.image_size, 1))\n",
    "\n",
    "        for name in all_imgs:\n",
    "            ## Reading Image\n",
    "            if \"img.jpg\" in name:\n",
    "                _img_path = os.path.join(img_path, name)\n",
    "                image = cv2.imread(_img_path, 1) # cv2.IMREAD_GRAYSCALE\n",
    "                image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "                # image = np.expand_dims(image, axis=-1)\n",
    "            ## Reading Masks\n",
    "            if (\"mask1.png\" in name): # or (\"mask2.png\" in name):\n",
    "                _mask_path = os.path.join(img_path, name)\n",
    "                _mask_image = cv2.imread(_mask_path, -1)\n",
    "                _mask_image = cv2.resize(_mask_image, (self.image_size, self.image_size)) #128x128\n",
    "                _mask_image = np.expand_dims(_mask_image, axis=-1)\n",
    "                mask = np.maximum(mask, _mask_image)\n",
    "            \n",
    "        ## Normalizaing \n",
    "        image = image/255.0\n",
    "        mask = mask/255.0\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if(index+1)*self.batch_size > len(self.ids):\n",
    "            self.batch_size = len(self.ids) - index*self.batch_size\n",
    "        \n",
    "        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        \n",
    "        image = []\n",
    "        mask  = []\n",
    "        \n",
    "        for id_name in files_batch:\n",
    "            _img, _mask = self.__load__(id_name)\n",
    "            image.append(_img)\n",
    "            mask.append(_mask)\n",
    "            \n",
    "        image = np.array(image)\n",
    "        mask  = np.array(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.ids)/float(self.batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf21710",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bcc4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "train_path = \"/mnt/Storage/Xuchu_Liu/Workspace/Python/FetalData/landmark dataset/A.P Diameter of Pons/\"\n",
    "epochs = 10\n",
    "batch_size = 1\n",
    "\n",
    "## Training Ids\n",
    "train_ids = next(os.walk(train_path))[1]\n",
    "\n",
    "## Validation Data Size\n",
    "val_data_size = 2\n",
    "\n",
    "valid_ids = train_ids[:val_data_size]\n",
    "train_ids = train_ids[val_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b51fb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3) (1, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "gen = DataGen(train_ids, train_path, batch_size=batch_size, image_size=image_size)\n",
    "x, y = gen.__getitem__(0)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13240ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1771f48d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = random.randint(0, len(x)-1)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(x[r])\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(y[r], (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d492cccf",
   "metadata": {},
   "source": [
    "## Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7185876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = keras.layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c66204",
   "metadata": {},
   "source": [
    "## Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a11fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# down_block(x, filters, kernel_size=(3, 3), \\\n",
    "#            padding=\"same\", strides=1):\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = keras.layers.MaxPool2D((2, 2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0d380",
   "metadata": {},
   "source": [
    "## Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b93d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# up_block(x, skip, filters, kernel_size=(3, 3), \\\n",
    "#              padding=\"same\", strides=1):\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = keras.layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb1d03",
   "metadata": {},
   "source": [
    "## UNET Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e488032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs = keras.layers.Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = keras.layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "\n",
    "    model = keras.models.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de22c02",
   "metadata": {},
   "source": [
    "## RUN the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38cb1610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 128 512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 128 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 256 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 512)  2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 512)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 1024) 4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  2097664     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 1024) 0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 512)  2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 512)  2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 524544      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 256 1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 256 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 256 590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 256 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 256 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 131200      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 128 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256, 128 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 128 147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 128 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 32832       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 512, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 512, 512, 64) 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 512, 512, 1)  65          activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 31,055,297\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_shape = (image_size, image_size, 3)\n",
    "    model = build_unet(input_shape)\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386afc0",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773f20c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate for 2 steps\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 8s 487ms/step - loss: 0.3307 - acc: 0.9209 - val_loss: 0.0217 - val_acc: 0.9988\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 0.1474 - acc: 0.9984 - val_loss: 0.7674 - val_acc: 0.9988\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 0.1041 - acc: 0.9985 - val_loss: 0.2241 - val_acc: 0.9988\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 0.0822 - acc: 0.9985 - val_loss: 0.1860 - val_acc: 0.9988\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.0664 - acc: 0.9985 - val_loss: 0.2237 - val_acc: 0.9988\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 0.0504 - acc: 0.9985 - val_loss: 0.2077 - val_acc: 0.9988\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 2s 125ms/step - loss: 0.0355 - acc: 0.9985 - val_loss: 0.2165 - val_acc: 0.9988\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 0.0308 - acc: 0.9985 - val_loss: 0.1427 - val_acc: 0.9988\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.0245 - acc: 0.9985 - val_loss: 0.1038 - val_acc: 0.9988\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.0217 - acc: 0.9985 - val_loss: 0.0726 - val_acc: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17603d1080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = DataGen(train_ids, train_path, image_size=image_size, batch_size=batch_size)\n",
    "valid_gen = DataGen(valid_ids, train_path, image_size=image_size, batch_size=batch_size)\n",
    "\n",
    "train_steps = len(train_ids)//batch_size\n",
    "valid_steps = len(valid_ids)//batch_size\n",
    "\n",
    "model.fit(train_gen, validation_data=valid_gen, steps_per_epoch=train_steps, validation_steps=valid_steps, \n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab9d77b",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cfd3034",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3abde450a45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## Dataset for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-docker/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-docker/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-docker/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-docker/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-docker/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/miniconda3/envs/tf-docker/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-docker/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    571\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "## Save the Weights\n",
    "model.save_weights(\"UNetW.h5\")\n",
    "\n",
    "## Dataset for prediction\n",
    "x, y = valid_gen.__getitem__(1)\n",
    "result = model.predict(x)\n",
    "\n",
    "result = result > 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(np.reshape(y[0]*255, (image_size, image_size)), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(result[0]*255, (image_size, image_size)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b558a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
